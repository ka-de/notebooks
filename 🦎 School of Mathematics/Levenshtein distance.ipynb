{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Levenshtein distance\n",
    "\n",
    "The Levenshtein distance, also known as the edit distance, is a way to measure how different two strings are by counting the minimum number of operations needed to transform one string into the other. These operations can be insertions, deletions, or substitutions of individual characters.\n",
    "\n",
    "Imagine you have two words, let's say \"kitten\" and \"sitting,\" and you want to find out how different they are using Levenshtein distance.\n",
    "\n",
    "Here's how it works step by step:\n",
    "\n",
    "1. First, we set up a grid, where one string is on the top (in this case \"kitten\") and the other is on the side (in this case \"sitting\"). Each cell in the grid represents a comparison between two characters, one from the top string and one from the side string.\n",
    "\n",
    "2. We start filling in the grid from the top-left corner to the bottom-right corner. At each cell, we compare the characters from the two strings. If they are the same, we don't need to do anything, and we simply copy the value from the diagonal cell above it.\n",
    "\n",
    "3. If the characters are different, we have three options:\n",
    "\n",
    "- **Insertion**: We can insert a character from the side string into the top string. This means we move to the cell above.\n",
    "- **Deletion**: We can delete a character from the top string. This means we move to the cell on the left.\n",
    "- **Substitution**: We can substitute one character with another. This means we move diagonally up and to the left.\n",
    "\n",
    "We keep filling in the grid, considering these three operations, until we reach the bottom-right corner of the grid. The number in that cell represents the Levenshtein distance between the two words. In our example, the Levenshtein distance between \"kitten\" and \"sitting\" is 3.\n",
    "\n",
    "$$\n",
    "\\operatorname{lev}(a, b) = \\begin{cases}\n",
    "  |a| & \\text{ if } |b| = 0, \\\\\n",
    "  |b| & \\text{ if } |a| = 0, \\\\\n",
    "  \\operatorname{lev}(\\text{tail}(a),\\text{tail}(b)) & \\text{ if } a[0] = b[0], \\\\\n",
    "  1 + \\min \\begin{cases}\n",
    "          \\operatorname{lev}(\\text{tail}(a), b) \\\\\n",
    "          \\operatorname{lev}(a, \\text{tail}(b)) \\\\\n",
    "          \\operatorname{lev}(\\text{tail}(a), \\text{tail}(b)) \\\\\n",
    "       \\end{cases} & \\text{ otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Here's how the formula relates to this process:\n",
    "\n",
    "* `lev(a, b)` represents the Levenshtein distance between strings `a` and `b`.\n",
    "* The formula starts by checking if either of the strings is empty (length is 0). If one of them is empty, the distance is simply the length of the other string.\n",
    "* If the first characters of the strings `a` and `b` are the same, we look at the Levenshtein distance between the remaining parts of the strings, which is calculated recursively.\n",
    "* If the first characters are different, we consider all three operations (insertion, deletion, substitution) and choose the one that minimizes the distance.\n",
    "\n",
    "In simpler terms, it's like solving a puzzle by finding the shortest path through the grid, where each cell represents a choice to either match characters, insert, delete, or substitute, and we're looking for the fewest steps to make the two strings the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Levenshtein distance between 'kitten' and 'sitting' is 3\n"
     ]
    }
   ],
   "source": [
    "def levenshtein_distance(s1, s2):\n",
    "    # Create a matrix to store the distances\n",
    "    matrix = [[0 for _ in range(len(s2) + 1)] for _ in range(len(s1) + 1)]\n",
    "\n",
    "    # Initialize the matrix\n",
    "    for i in range(len(s1) + 1):\n",
    "        matrix[i][0] = i\n",
    "    for j in range(len(s2) + 1):\n",
    "        matrix[0][j] = j\n",
    "\n",
    "    # Fill in the matrix\n",
    "    for i in range(1, len(s1) + 1):\n",
    "        for j in range(1, len(s2) + 1):\n",
    "            cost = 0 if s1[i - 1] == s2[j - 1] else 1\n",
    "            matrix[i][j] = min(\n",
    "                matrix[i - 1][j] + 1,         # Deletion\n",
    "                matrix[i][j - 1] + 1,         # Insertion\n",
    "                matrix[i - 1][j - 1] + cost  # Substitution\n",
    "            )\n",
    "\n",
    "    # The final value in the matrix is the Levenshtein distance\n",
    "    return matrix[len(s1)][len(s2)]\n",
    "\n",
    "# Example usage:\n",
    "s1 = \"kitten\"\n",
    "s2 = \"sitting\"\n",
    "distance = levenshtein_distance(s1, s2)\n",
    "print(f\"The Levenshtein distance between '{s1}' and '{s2}' is {distance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fuzzywuzzy is a Python library that provides a simple and easy-to-use way to calculate string similarity or similarity ratios between strings. It's often used for tasks like fuzzy string matching and approximate string comparison. Fuzzywuzzy uses the Levenshtein distance (edit distance) as one of its underlying algorithms to compute these similarity scores.\n",
    "\n",
    "**String Comparison**: Fuzzywuzzy allows you to compare two strings and obtain a similarity score, often referred to as a \"fuzzy match score.\" This score indicates how similar the two strings are based on their characters and the number of operations (insertions, deletions, substitutions) needed to transform one string into the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score: 91%\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "string1 = \"apple\"\n",
    "string2 = \"apples\"\n",
    "\n",
    "# Calculate similarity score between string1 and string2\n",
    "similarity_score = fuzz.ratio(string1, string2)\n",
    "print(f\"Similarity Score: {similarity_score}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Partial Ratio**: One of the functions provided by Fuzzywuzzy is `fuzz.partial_ratio()`. This function calculates the similarity ratio between two strings, considering the best partial match. It's particularly useful when you want to find a subsequence of characters that closely matches within a longer string. The partial ratio function uses the Levenshtein distance to calculate this score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial Ratio: 72%\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "string1 = \"programming in Python is fun\"\n",
    "string2 = \"Python programming is really fun\"\n",
    "\n",
    "# Calculate partial ratio between string1 and string2\n",
    "partial_ratio = fuzz.partial_ratio(string1, string2)\n",
    "print(f\"Partial Ratio: {partial_ratio}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Token Set Ratio**: Fuzzywuzzy also offers `fuzz.token_set_ratio()`, which is handy when comparing sets of words (tokens) within strings. It calculates the similarity based on the intersection and difference of tokens in the two strings while considering the order of words. This function employs the Levenshtein distance for its computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Set Ratio: 81%\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "string1 = \"data science in Python is interesting\"\n",
    "string2 = \"Python is great for data science\"\n",
    "\n",
    "# Calculate token set ratio between string1 and string2\n",
    "token_set_ratio = fuzz.token_set_ratio(string1, string2)\n",
    "print(f\"Token Set Ratio: {token_set_ratio}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scoring Mechanism**: Fuzzywuzzy uses the Levenshtein distance algorithm to compute the number of edit operations required to make one string match another. It then converts this into a percentage or ratio to provide a similarity score. The higher the score, the more similar the strings are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score: 62%\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "string1 = \"kitten\"\n",
    "string2 = \"sitting\"\n",
    "\n",
    "# Calculate similarity score between string1 and string2\n",
    "similarity_score = fuzz.ratio(string1, string2)\n",
    "print(f\"Similarity Score: {similarity_score}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Customizable Thresholds**: Fuzzywuzzy allows you to set a similarity threshold, and you can use this threshold to filter out results that fall below a certain similarity score. This can be useful in applications like string deduplication or fuzzy string matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strings are similar.\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "string1 = \"apple\"\n",
    "string2 = \"apples\"\n",
    "\n",
    "# Calculate similarity score between string1 and string2\n",
    "similarity_score = fuzz.ratio(string1, string2)\n",
    "\n",
    "# Set a similarity threshold (e.g., 80%)\n",
    "threshold = 80\n",
    "\n",
    "if similarity_score >= threshold:\n",
    "    print(\"Strings are similar.\")\n",
    "else:\n",
    "    print(\"Strings are not similar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Practical Use Cases**: Fuzzywuzzy is often used in scenarios where approximate string matching is required, such as deduplication of records in databases, spell-checking, and search engines. It's valuable when dealing with user-generated text that may contain typos, abbreviations, or slight variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Strings: ['apple', 'banana', 'app']\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "# Sample list of strings (possibly containing duplicates)\n",
    "strings = [\"apple\", \"apples\", \"appl\", \"banana\", \"app\"]\n",
    "\n",
    "# Deduplicate the list based on a similarity threshold (e.g., 80%)\n",
    "threshold = 80\n",
    "\n",
    "# Create a dictionary to store unique strings\n",
    "unique_strings = {}\n",
    "\n",
    "for string in strings:\n",
    "    # Check if a similar string is already in the unique_strings dictionary\n",
    "    found_similar = False\n",
    "    for key in unique_strings.keys():\n",
    "        if fuzz.ratio(string, key) >= threshold:\n",
    "            found_similar = True\n",
    "            break\n",
    "    if not found_similar:\n",
    "        unique_strings[string] = True\n",
    "\n",
    "# Extract the unique strings\n",
    "unique_strings_list = list(unique_strings.keys())\n",
    "print(\"Unique Strings:\", unique_strings_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, Fuzzywuzzy is used to deduplicate a list of strings by comparing each string to the existing unique strings based on a similarity threshold. If a similar string is found, it's not added to the `unique_strings dictionary`. This can be useful for cleaning up datasets or lists with potentially similar entries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
